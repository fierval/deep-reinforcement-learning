{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/).\n",
    "\n",
    "Install Tensorboard extension for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboardX in c:\\anaconda3\\envs\\agents\\lib\\site-packages (1.6)\n",
      "Requirement already satisfied: protobuf>=3.2.0 in c:\\anaconda3\\envs\\agents\\lib\\site-packages (from tensorboardX) (3.7.0)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\envs\\agents\\lib\\site-packages (from tensorboardX) (1.16.2)\n",
      "Requirement already satisfied: six in c:\\anaconda3\\envs\\agents\\lib\\site-packages (from tensorboardX) (1.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda3\\envs\\agents\\lib\\site-packages (from protobuf>=3.2.0->tensorboardX) (40.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Reacher_Windows_20/Reacher')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train with DDPG\n",
    "\n",
    "Using TensorBoard to visualize the results during training. It will store logs in the \"runs\" subdirectory of the root:\n",
    "\n",
    "`tensorboard --logdir runs/<name_of_run> --host localhost --port 8080`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddpg_agent import Agent, N_EPISODES, MAX_T\n",
    "from utils import distr_projection, RewardTracker, TBMeanTracker\n",
    "import time\n",
    "import torch\n",
    "\n",
    "SOLVED_SCORE = 30\n",
    "MEAN_WINDOW = 100\n",
    "\n",
    "n_episodes = N_EPISODES\n",
    "max_t = MAX_T\n",
    "\n",
    "#agent = D4PGAgent(num_agents, state_size, action_size, 1)\n",
    "agent = Agent(num_agents, state_size, action_size, 1)\n",
    "max_score = -np.Inf\n",
    "solved_episode = -np.Inf\n",
    "\n",
    "# Tensorboard based reward tracker\n",
    "reward_tracker = RewardTracker(agent.writer, MEAN_WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i_episode in range(1, n_episodes+1):\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    states = env_info.vector_observations\n",
    "    scores = np.zeros(num_agents)\n",
    "\n",
    "    # noise reset\n",
    "    #agent.reset()\n",
    "    start_time = time.time()\n",
    "    for t in range(max_t):\n",
    "        actions = agent.act(states)\n",
    "\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "            agent.step(state, action, reward, next_state, done, t)             \n",
    "        states = next_states\n",
    "\n",
    "        scores += rewards\n",
    "\n",
    "        if np.any(dones):\n",
    "            break\n",
    "\n",
    "    # does all the right things with reward tracking\n",
    "    duration = time.time() - start_time\n",
    "    score = np.mean(scores)\n",
    "    mean_reward = reward_tracker.reward(scores, score, agent.step_t, duration)\n",
    "    \n",
    "    # save stuff for the report\n",
    "    if i_episode == 1 or i_episode == 50 or i_episode == 100:\n",
    "        torch.save(agent.actor_local.state_dict(), f'checkpoint_actor_{i_episode:03d}.pth')\n",
    "        torch.save(agent.critic_local.state_dict(), f'checkpoint_critic_{i_episode:03f}.pth')\n",
    "        \n",
    "        max_score = score\n",
    "\n",
    "    if mean_reward is not None and mean_reward >=  SOLVED_SCORE:\n",
    "        torch.save(agent.actor_local.state_dict(), f'checkpoint_actor.pth')\n",
    "        torch.save(agent.critic_local.state_dict(), f'checkpoint_critic.pth')\n",
    "        \n",
    "        solved_episode = i_episode - MEAN_WINDOW - 1\n",
    "        print(f\"Solved in {solved_episode} episodes\")\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(reward_tracker.total_rewards)), reward_tracker.total_rewards, label='Rewards')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Load trained model and give it a go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 7.7958e-01,  1.4383e+00,  1.6180e+00,  ...,  4.7685e-02,\n",
       "                       -4.2120e-02,  2.6608e+00],\n",
       "                      [ 5.9436e-01, -1.6794e-01, -1.0412e+00,  ...,  4.1936e-02,\n",
       "                       -2.7712e-02,  6.5785e+00],\n",
       "                      [-1.3552e+00, -5.9403e-01, -8.9958e-01,  ..., -4.3487e-02,\n",
       "                        4.7516e-02, -2.3183e+00],\n",
       "                      ...,\n",
       "                      [ 1.7507e+00, -2.8608e-01,  4.1710e-01,  ..., -8.9364e-03,\n",
       "                        6.8252e-04,  4.1534e-01],\n",
       "                      [ 6.9746e-01,  2.6662e+00,  7.0807e-01,  ...,  4.4592e-02,\n",
       "                       -3.8226e-02, -7.8190e-01],\n",
       "                      [-1.9762e-01, -8.5767e-02, -2.5576e-01,  ..., -3.7095e-02,\n",
       "                       -2.9657e-02, -3.0729e-01]], device='cuda:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 4.8758e-02,  1.5518e-01,  9.1859e-02,  2.8538e-02, -1.1765e-01,\n",
       "                       1.1607e-01, -1.5044e-05,  5.7687e-02, -8.2638e-02, -1.4442e-01,\n",
       "                      -1.5519e-01, -5.2529e-02, -1.2902e-01, -1.5051e-01,  1.7182e-01,\n",
       "                       6.8672e-02, -2.3025e-02, -1.5288e-01, -1.2311e-01, -1.6467e-01,\n",
       "                      -4.3248e-02,  1.2372e-01, -2.2981e-02,  3.8527e-02, -1.2725e-02,\n",
       "                       1.0543e-01,  1.6662e-01, -7.0922e-02, -1.3411e-01,  1.0224e-01,\n",
       "                       1.1521e-01,  1.3554e-02, -7.8216e-02, -4.0591e-02,  9.8324e-02,\n",
       "                       5.2171e-02, -6.0577e-02,  4.9362e-02,  5.3312e-02, -5.0456e-02,\n",
       "                      -1.0006e-01,  4.2375e-02,  4.2596e-02,  1.6867e-01, -2.8386e-02,\n",
       "                       2.5955e-02,  3.8506e-02,  7.8234e-02,  8.1831e-02, -1.2147e-01,\n",
       "                       1.4779e-01,  3.4228e-02,  1.7393e-01, -1.3356e-01,  1.5497e-01,\n",
       "                       1.2741e-01, -6.6002e-02, -1.6056e-01,  2.8231e-02,  1.0619e-01,\n",
       "                      -8.8854e-02,  7.1582e-02,  2.7754e-02,  1.4766e-01,  1.6973e-01,\n",
       "                       7.8605e-02, -3.0378e-02, -5.8357e-02,  1.2250e-01, -9.4009e-02,\n",
       "                      -6.4415e-02, -1.0266e-01, -1.7398e-01,  1.5675e-01,  1.1224e-01,\n",
       "                       7.1067e-02,  1.2872e-01,  1.2398e-01,  1.2022e-01, -1.1398e-01,\n",
       "                       1.1369e-01, -1.2704e-02,  1.6706e-01,  1.5325e-01,  3.8697e-02,\n",
       "                      -9.3783e-02,  1.6378e-01, -1.7316e-01, -7.4404e-02,  5.1883e-02,\n",
       "                       2.0184e-02, -1.3183e-01, -1.0196e-01,  3.3689e-02, -3.3927e-02,\n",
       "                      -1.4053e-01,  1.0100e-01,  1.2834e-01, -1.6853e-02,  8.9070e-02,\n",
       "                       3.6304e-02,  9.6337e-02,  1.1347e-03,  5.2410e-02,  1.2122e-01,\n",
       "                      -5.3856e-02,  1.2493e-01,  4.8712e-02, -1.4100e-01,  1.3869e-01,\n",
       "                      -6.8367e-02, -1.7019e-01, -4.3794e-02, -1.7239e-01, -4.9857e-02,\n",
       "                      -4.2980e-02, -1.2465e-01,  1.4159e-01,  1.0876e-01,  8.7888e-02,\n",
       "                       1.6062e-01, -7.1221e-02,  6.7267e-02,  1.2950e-01,  1.3956e-01,\n",
       "                       6.3760e-02,  7.9576e-02,  1.5762e-01,  1.4551e-01, -1.3880e-01,\n",
       "                       1.4322e-01, -6.8277e-02,  1.1313e-01, -1.6958e-01,  1.5543e-01,\n",
       "                       1.4499e-01, -4.9655e-02,  1.5929e-01,  3.4715e-02, -1.1462e-01,\n",
       "                       6.8683e-02, -1.1014e-01, -9.0728e-02,  1.4941e-01,  5.0489e-03,\n",
       "                      -9.4709e-02, -1.6670e-01, -9.0992e-03,  1.9707e-02, -3.0215e-02,\n",
       "                       8.0671e-03,  1.4249e-01, -1.5918e-01,  4.0700e-02, -1.9854e-02,\n",
       "                      -1.5382e-01, -1.6976e-01, -8.4264e-03, -1.6760e-01,  1.7200e-01,\n",
       "                      -1.4821e-01, -4.9273e-03, -4.1788e-03, -1.0148e-01,  1.6289e-01,\n",
       "                      -2.5073e-02, -6.7175e-02,  1.4067e-01,  5.6070e-02, -5.2214e-02,\n",
       "                      -1.6890e-01, -3.2847e-02, -4.3318e-02, -4.7404e-02,  1.0305e-01,\n",
       "                      -1.2920e-02,  4.7529e-02,  1.4197e-01,  3.0314e-03,  1.6438e-01,\n",
       "                       7.3190e-02, -1.3036e-01,  8.7446e-02, -7.2257e-02,  1.3729e-01,\n",
       "                       4.8928e-02, -1.0517e-01, -1.0497e-01, -1.7233e-01, -1.6665e-01,\n",
       "                      -1.1058e-01,  4.4653e-02, -4.9828e-02,  3.3917e-02, -1.4864e-01,\n",
       "                      -8.9291e-04, -8.2486e-02,  4.5600e-02, -1.2078e-01,  8.3470e-02,\n",
       "                      -7.2504e-02,  1.9000e-02, -7.4497e-02,  1.4774e-01,  1.6156e-02,\n",
       "                       8.4750e-02, -6.8600e-02,  1.3953e-01, -6.4749e-02,  1.1079e-01,\n",
       "                       1.6711e-01, -8.8200e-02,  3.9486e-02,  3.5454e-02, -7.5601e-04,\n",
       "                       7.5078e-02,  1.5390e-01, -1.1733e-03,  4.2701e-02,  1.0813e-01,\n",
       "                      -1.4356e-01,  1.0287e-01,  5.4495e-03, -1.2667e-01,  7.1423e-02,\n",
       "                      -7.9954e-02, -1.2806e-01, -5.7225e-02,  2.2323e-02,  1.0042e-01,\n",
       "                      -7.7211e-02,  1.4597e-01, -1.2359e-01, -1.2731e-01,  6.8519e-02,\n",
       "                       1.6380e-01,  1.3176e-01,  1.2420e-01,  1.0122e-02, -6.1863e-02,\n",
       "                      -1.2909e-01, -1.2420e-01,  5.3780e-02, -1.2100e-02, -2.7628e-02,\n",
       "                      -3.3039e-02, -2.3243e-04, -1.0200e-01, -3.9437e-02,  1.4273e-01,\n",
       "                      -9.2467e-02, -1.2306e-02, -1.3753e-01, -6.9555e-02,  5.8805e-02,\n",
       "                       7.5349e-02, -1.4392e-01,  1.3229e-01,  4.0626e-02,  8.3053e-02,\n",
       "                      -1.0126e-01,  1.1944e-01, -1.5851e-01, -1.3370e-01,  1.1719e-01,\n",
       "                      -5.4468e-02,  7.3926e-02,  8.4455e-02, -7.3874e-02, -1.0645e-01,\n",
       "                       9.6608e-02,  1.1569e-01, -1.1541e-03,  2.7322e-02,  6.9185e-02,\n",
       "                       5.6326e-02,  1.6223e-01,  4.6110e-03, -9.0791e-02, -7.6361e-02,\n",
       "                      -1.1323e-01, -4.1088e-03,  3.3160e-02,  1.0059e-02,  1.4083e-01,\n",
       "                      -5.1380e-03,  1.5322e-01, -1.6727e-02, -4.4168e-02,  1.1216e-01,\n",
       "                       4.9270e-02, -1.2444e-01,  2.8536e-02, -1.7277e-01, -1.1476e-01,\n",
       "                      -1.2784e-01, -1.2740e-02, -5.5926e-02,  1.5547e-01, -8.5894e-02,\n",
       "                      -4.2207e-02, -1.0523e-01, -9.5063e-02,  7.7962e-02,  1.0407e-01,\n",
       "                      -1.3187e-01,  1.6166e-01,  1.1357e-02,  7.1446e-02, -1.2255e-02,\n",
       "                      -1.8783e-02,  1.3355e-01, -5.8484e-02,  3.9083e-02,  9.4226e-02,\n",
       "                      -1.5926e-01,  8.8109e-03, -1.1860e-01, -1.5979e-01, -3.7914e-02,\n",
       "                      -8.6783e-03, -6.9211e-02, -4.1687e-02, -8.6375e-02,  1.4156e-01,\n",
       "                      -1.2586e-01, -1.5572e-02,  2.1216e-02,  8.9269e-02, -5.4338e-02,\n",
       "                       7.4239e-02, -1.5620e-01, -1.6300e-01, -6.9318e-02,  7.1895e-02,\n",
       "                      -5.1120e-02,  1.6288e-01,  1.1834e-02,  1.5538e-01,  1.0424e-01,\n",
       "                       7.5972e-02,  6.5705e-02, -1.2916e-01, -3.5196e-02,  7.2273e-02,\n",
       "                      -1.6374e-01, -8.3032e-02, -1.6951e-01,  1.0648e-01,  9.6821e-02,\n",
       "                      -6.6838e-02, -1.0877e-01, -1.3972e-01, -2.6740e-02,  5.0094e-02,\n",
       "                       1.1970e-01, -1.3965e-01, -2.0208e-02,  5.5723e-02, -1.2438e-01,\n",
       "                      -6.9835e-02,  1.0970e-01, -1.4555e-01, -3.3951e-02, -8.4741e-03,\n",
       "                       4.0943e-02,  1.7160e-01, -3.8724e-02, -3.1170e-02, -7.3071e-02,\n",
       "                       1.3261e-01,  1.4036e-01,  1.4795e-01, -9.4190e-02,  1.2358e-01,\n",
       "                      -1.5489e-01, -1.1770e-02, -5.0841e-02,  2.4128e-02, -3.9802e-02,\n",
       "                      -1.3468e-01, -9.7978e-02, -4.6197e-03, -1.0392e-01, -4.9032e-02,\n",
       "                      -7.9996e-02, -1.3224e-01,  1.5348e-01, -1.5915e-01,  7.1475e-02,\n",
       "                      -1.3551e-01, -1.2195e-01,  2.4004e-02,  1.4469e-01, -7.2775e-02,\n",
       "                      -2.8922e-02,  7.7705e-02,  1.7001e-01,  1.0829e-01, -1.3790e-01],\n",
       "                     device='cuda:0')),\n",
       "             ('bn1.weight',\n",
       "              tensor([ 5.3975e-01,  7.6263e-01,  5.7860e-01,  1.1292e+00, -7.3717e-01,\n",
       "                       6.7355e-01,  6.7184e-01,  1.1368e+00,  9.3871e-01,  1.0086e+00,\n",
       "                       5.1201e-01,  1.0222e+00,  6.6161e-01,  1.1186e+00,  7.8832e-01,\n",
       "                       7.5584e-01,  7.0014e-01,  1.1288e+00,  7.3079e-01,  6.1920e-01,\n",
       "                       1.0479e+00,  7.7354e-01,  5.6724e-01,  1.1832e+00,  8.7808e-01,\n",
       "                       7.0272e-01,  1.2675e+00,  8.5382e-01,  6.2822e-01,  3.3068e-01,\n",
       "                       5.3276e-01,  1.1448e+00,  1.0009e+00,  1.1453e+00,  1.2083e+00,\n",
       "                       5.7833e-01,  6.6614e-01,  1.2697e+00,  9.4881e-01,  8.5044e-01,\n",
       "                       6.9951e-01,  1.9972e-01,  1.0633e+00,  6.3632e-01,  7.6322e-01,\n",
       "                       1.0118e+00,  3.1160e-01,  3.8454e-01,  9.5829e-01,  9.3977e-01,\n",
       "                       6.1657e-01,  6.7120e-01,  4.8477e-01,  9.6980e-01,  3.2380e-01,\n",
       "                       3.3815e-01,  1.1150e+00,  7.5140e-01,  7.2995e-01,  4.4815e-01,\n",
       "                       8.1509e-01,  8.0211e-01,  1.1436e+00,  8.8577e-01,  6.8525e-01,\n",
       "                       8.3031e-01,  9.5231e-01,  4.3412e-01,  7.1217e-01,  6.1136e-01,\n",
       "                       3.2822e-01,  1.1566e+00,  1.4603e+00,  7.4833e-01,  8.1214e-01,\n",
       "                       9.9055e-01,  7.5094e-01,  6.9674e-01,  8.8997e-01,  1.1006e+00,\n",
       "                       6.2003e-01,  9.1125e-01,  2.5484e-03,  7.6241e-01,  8.5978e-01,\n",
       "                      -9.0535e-04,  7.5554e-01,  9.0993e-01,  6.0330e-01,  1.1985e+00,\n",
       "                       6.2126e-01,  6.7292e-01,  7.2205e-01,  7.2493e-01,  6.8152e-01,\n",
       "                       6.8607e-01,  1.2585e+00,  5.2802e-01,  6.7863e-01,  1.0321e+00,\n",
       "                       7.4261e-01,  7.7392e-01,  5.6586e-01,  7.4959e-01,  1.1105e+00,\n",
       "                       5.0845e-01,  1.2098e+00,  5.7224e-01,  5.7618e-01,  8.6442e-01,\n",
       "                       7.5218e-01,  9.8388e-01,  5.8796e-01,  5.5492e-01,  1.0535e+00,\n",
       "                       1.0073e+00,  1.3010e+00,  4.2298e-01,  8.6140e-01,  7.9609e-01,\n",
       "                       2.0926e-01,  9.3782e-01,  8.2899e-01,  8.4810e-01,  8.1482e-01,\n",
       "                       6.4891e-01,  5.2437e-01,  7.2583e-01,  8.4479e-01,  4.5479e-04,\n",
       "                       7.5354e-01,  7.7982e-01,  8.2671e-01,  5.2163e-01,  5.4437e-01,\n",
       "                       9.8090e-01,  7.2248e-01,  1.0443e+00,  9.2732e-01,  5.5651e-01,\n",
       "                       7.4339e-01,  7.4061e-01,  4.9242e-01,  9.7262e-01,  7.4572e-01,\n",
       "                       7.8427e-01,  4.6211e-01,  4.9680e-01,  4.5997e-01,  2.4908e-01,\n",
       "                       1.0218e+00,  4.7600e-01,  9.2597e-01,  9.1103e-01,  1.1704e+00,\n",
       "                       1.0893e+00,  8.1372e-01,  5.4857e-01,  7.6551e-01,  7.8087e-01,\n",
       "                       9.3135e-01,  6.8154e-01,  9.9964e-01,  8.2931e-01,  7.5487e-01,\n",
       "                       8.9715e-01,  9.3893e-01,  5.7522e-01,  8.5097e-01,  4.6615e-01,\n",
       "                       8.2806e-01,  6.9929e-01,  5.7631e-04,  5.6272e-01,  1.0082e+00,\n",
       "                       3.7694e-01,  8.7892e-01,  1.0223e+00,  6.8531e-01,  1.3304e+00,\n",
       "                       6.8764e-01,  8.7071e-01,  6.4718e-01,  7.5010e-01,  6.4929e-01,\n",
       "                       7.0363e-01,  8.4523e-01,  8.8563e-01,  6.2159e-01,  9.6511e-01,\n",
       "                       4.0186e-01,  1.7175e+00,  8.0937e-01,  5.8204e-01,  5.0955e-01,\n",
       "                       5.8325e-01,  6.4595e-01,  8.0383e-01,  3.5804e-01,  8.3710e-01,\n",
       "                       1.0286e+00,  3.9371e-01,  7.9880e-01,  6.0043e-01,  1.2296e+00,\n",
       "                       8.0799e-01,  7.2563e-01,  6.8067e-01,  6.3323e-01,  2.2967e-03,\n",
       "                       1.7722e+00,  8.2007e-01,  7.0860e-01,  1.0777e+00,  2.8671e-01,\n",
       "                       9.8429e-01,  5.6922e-01,  5.6850e-01,  6.3246e-01,  7.8095e-01,\n",
       "                       6.1049e-01,  9.9230e-01,  7.7948e-01,  6.3849e-01,  7.8929e-01,\n",
       "                       5.1416e-01,  7.2943e-01,  4.9619e-01,  7.1472e-01,  7.4149e-01,\n",
       "                       6.4596e-01,  6.7903e-01,  4.4084e-01, -1.9106e-03,  4.4109e-01,\n",
       "                       7.9821e-01,  5.9564e-01,  5.1655e-01,  1.1472e+00,  8.7078e-01,\n",
       "                       8.3649e-01,  8.3877e-01,  5.7218e-01,  4.2233e-01,  6.8129e-01,\n",
       "                       1.0202e+00,  6.3213e-01,  1.0510e+00,  8.6186e-01,  7.8668e-01,\n",
       "                       7.1679e-01,  8.4742e-01,  3.7980e-01,  5.0919e-01,  8.7958e-01,\n",
       "                       6.5134e-01,  6.8816e-01,  5.8049e-01,  9.4365e-01,  1.3380e+00,\n",
       "                       8.4922e-01,  9.8527e-01,  6.0826e-01,  1.2593e+00,  7.4926e-01,\n",
       "                       4.9257e-01,  6.8462e-01,  6.6982e-01,  4.2354e-01,  9.9645e-01,\n",
       "                       8.6828e-01,  8.7677e-01, -9.0525e-03,  3.2575e-01,  3.8850e-01,\n",
       "                       5.4785e-01,  8.8498e-01,  9.1281e-01,  6.7521e-01,  4.9512e-01,\n",
       "                       8.9393e-01,  4.6239e-01,  8.1065e-01,  5.3023e-01,  4.2547e-01,\n",
       "                       7.6099e-01,  8.6188e-01,  1.1570e+00,  8.0595e-01,  6.3813e-01,\n",
       "                       9.9914e-01,  4.3130e-01,  1.1031e+00,  9.6455e-01,  8.3140e-01,\n",
       "                       7.9221e-01,  1.7422e-01,  1.1673e+00,  9.7791e-01,  7.8458e-01,\n",
       "                       3.2610e-01,  1.0128e+00,  7.0103e-01,  7.5724e-01,  7.6764e-01,\n",
       "                       8.7546e-01,  7.9584e-01,  9.5024e-01,  1.0689e+00,  7.2237e-01,\n",
       "                       1.0053e+00,  2.2215e-01,  7.6462e-01,  8.4669e-01,  4.4964e-01,\n",
       "                      -1.6071e-03,  7.0960e-01,  9.1513e-01,  8.2154e-01,  7.1463e-01,\n",
       "                       7.6408e-01,  6.3098e-01,  7.5104e-01,  8.6409e-01,  9.1362e-01,\n",
       "                       1.4094e+00,  6.9572e-01,  4.8737e-01,  2.4128e-01,  9.4072e-01,\n",
       "                       6.0300e-01,  6.7365e-01,  8.4657e-01,  8.2099e-01,  6.5842e-01,\n",
       "                       7.3848e-01,  1.0867e+00,  8.1262e-01,  9.8328e-01,  8.0209e-01,\n",
       "                       9.7429e-01,  9.6723e-01,  1.0049e+00,  9.2916e-01,  9.9628e-01,\n",
       "                       9.4911e-01,  6.1557e-01,  6.1759e-01,  5.0921e-01,  8.3573e-01,\n",
       "                       9.9959e-01,  4.8853e-01,  1.3962e+00,  1.1506e+00,  6.8771e-01,\n",
       "                       6.0983e-01,  8.0862e-01,  3.6810e-01,  1.2281e+00,  9.6143e-01,\n",
       "                       9.5980e-01,  7.5823e-01,  8.8125e-01,  1.4020e+00,  7.3247e-01,\n",
       "                       1.2544e+00,  8.0261e-01,  5.7205e-01,  1.7499e+00,  9.5036e-01,\n",
       "                       4.5013e-01,  9.7004e-01,  7.1864e-01,  9.8056e-01,  4.6606e-01,\n",
       "                       1.0204e+00,  8.1345e-01,  4.5910e-01,  5.9830e-01,  5.6474e-01,\n",
       "                       1.0936e+00,  8.8888e-01,  1.1529e+00,  6.2877e-01,  1.1129e+00,\n",
       "                       5.6903e-01,  1.2191e+00,  6.6208e-01,  4.0815e-01,  6.8569e-01,\n",
       "                       3.5119e-01,  1.1855e+00,  4.8959e-03,  5.9361e-01,  9.1780e-01,\n",
       "                       6.7559e-01,  9.7769e-01,  7.6383e-01,  5.5361e-01,  3.2063e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('bn1.bias',\n",
       "              tensor([-0.9855, -1.3527, -0.6056, -0.8484, -1.1135, -0.8159, -0.9466, -1.6248,\n",
       "                      -0.2413, -1.1487, -0.3334, -0.9239, -0.4033, -1.2910, -0.7602, -1.4130,\n",
       "                      -1.0404, -0.8181, -0.9111, -0.7280, -0.9862, -0.6259, -0.6191, -1.3160,\n",
       "                      -1.3557, -0.4858, -0.9311, -1.0203, -0.6897,  0.0725, -0.6403, -1.1799,\n",
       "                      -1.3250, -0.9488, -0.7216, -0.4112, -0.8039, -1.7070, -0.9905, -0.9208,\n",
       "                      -0.8000,  1.2186, -1.0607, -1.4369, -0.8869, -1.1667, -0.2256,  0.0578,\n",
       "                      -1.0025, -0.6210, -1.3837, -0.6524, -0.6796,  0.1748, -0.0845, -0.4507,\n",
       "                      -1.1800, -0.9718, -0.9824, -0.4684, -1.0691, -0.9805, -1.1090, -0.5707,\n",
       "                      -0.1976, -0.6611, -1.2846, -0.0200, -0.8039, -1.0979, -1.4610, -0.4230,\n",
       "                      -1.4935, -0.9758, -0.8721, -0.9953, -1.2768, -0.5940, -1.0797, -0.6394,\n",
       "                      -0.8460, -1.0445, -0.0159, -1.1669, -0.5036, -0.0090, -0.9639, -1.1098,\n",
       "                      -0.4126, -1.2903, -0.7456, -1.0496, -0.4378, -1.1136, -0.7944, -1.4049,\n",
       "                      -1.1484, -0.4244, -0.7959, -1.0758, -0.8889, -0.5248, -0.4918, -1.1416,\n",
       "                      -1.5664, -0.6573, -1.0717,  0.2148, -0.3324, -1.1228, -0.7405, -0.9709,\n",
       "                      -0.7294, -0.8643, -0.5571, -0.7755, -1.0122, -0.5531, -0.5796, -0.9218,\n",
       "                      -0.0117, -1.2327, -0.6346, -0.5825, -0.7606, -0.7398, -0.3512, -0.2889,\n",
       "                      -0.8396, -0.0108, -0.7935, -1.0329, -0.6304, -0.6975, -0.7274, -0.9213,\n",
       "                      -0.8318, -1.3899, -0.8973,  0.0397, -1.0274, -0.9835, -0.7389, -0.5175,\n",
       "                      -1.0920, -0.6399, -0.5403, -0.6432, -0.1532, -1.3341, -0.6746, -0.4240,\n",
       "                      -0.6719, -0.4813, -0.7707, -1.3463, -1.3789,  0.0178, -1.0627, -0.6963,\n",
       "                      -0.4929, -0.6149, -1.2418, -1.2951, -0.6775, -1.1732, -0.8398, -1.0709,\n",
       "                      -1.2860, -0.3325, -0.9463, -0.8238, -0.0086, -0.8291, -0.8127, -0.2530,\n",
       "                      -0.9665, -0.6572, -1.2255, -0.9851, -0.4124, -0.2211, -0.5169, -0.5361,\n",
       "                      -0.3277, -0.2937, -1.0921, -0.5494, -0.5678, -0.9576, -0.5205, -1.5272,\n",
       "                      -0.8878, -0.4057, -0.9203, -0.7769, -0.8233, -0.7542, -1.3979, -0.8218,\n",
       "                      -1.4479, -0.2954, -1.1967, -0.8751, -0.9756, -1.0449, -0.9300, -0.9619,\n",
       "                      -0.0969, -0.0415,  0.2223, -0.4067, -0.1567, -1.0071, -0.1393, -1.3689,\n",
       "                      -1.2804, -1.1582, -0.9235, -1.0847, -0.4918, -1.2549, -1.1503, -0.6142,\n",
       "                      -0.8700, -1.2955, -0.7980, -0.2522, -0.8070, -1.1930, -0.8632, -0.9565,\n",
       "                      -0.1449, -0.0137, -0.4265, -0.7236, -0.6872, -0.1358, -1.1547, -0.7885,\n",
       "                      -0.9218,  0.3559, -0.5001, -0.8509, -0.9447, -1.0137, -0.8925, -1.0903,\n",
       "                      -1.0223, -0.5976, -1.0116, -0.5279,  0.0356, -0.2980, -1.3084, -0.6448,\n",
       "                      -1.1823, -0.6863, -1.1462, -1.6563, -0.3385, -1.0135, -0.7413, -1.4703,\n",
       "                      -0.7524, -0.4264, -0.5880, -1.1369, -0.3177, -0.5170, -1.2830, -1.3000,\n",
       "                      -0.1029, -1.6012, -0.2743, -0.5090, -1.0933, -1.3330, -0.4936, -0.2240,\n",
       "                      -0.9250, -0.5174, -0.1263, -1.0998, -1.6772, -0.8145, -1.5443,  0.0728,\n",
       "                      -0.9371, -0.5153, -0.4906, -0.8209, -0.8864, -0.9874, -1.0662, -0.8890,\n",
       "                      -1.1451, -1.2803, -1.4037, -0.4244, -0.4666, -1.1612, -0.2797, -1.2478,\n",
       "                      -1.3342, -0.8966, -0.8691, -1.2033, -0.6562, -0.8921, -1.2382, -0.9941,\n",
       "                      -0.8056, -1.0491, -0.8413, -0.0519, -0.7702, -1.1359, -1.1360, -0.5803,\n",
       "                      -0.9875, -0.5146, -0.7474, -0.9691, -1.1439, -0.7277, -1.2248, -0.3257,\n",
       "                       0.0839, -0.5014, -0.9644, -1.0881, -1.2261, -1.3002, -0.1496, -1.0022,\n",
       "                      -1.5470, -0.7548, -0.9117, -0.5234, -0.8744, -0.6619, -0.7250, -1.0791,\n",
       "                      -0.8632, -0.9891, -0.0060, -0.8271, -1.7660, -1.1258, -1.0343, -0.6416,\n",
       "                      -1.6123, -1.1332, -0.5139, -0.8143, -1.3184, -1.9034, -0.8544, -1.1072,\n",
       "                      -1.2268, -0.9689, -0.8222, -2.8035,  0.0705, -1.5122, -1.3070, -0.4390,\n",
       "                      -2.2130, -0.3838, -0.1015, -1.3179, -0.1031, -0.9853, -0.2449, -1.2281,\n",
       "                      -0.7720, -0.6142, -0.5873, -0.4435, -0.9000, -0.9924, -0.9209, -0.6493,\n",
       "                      -1.0865, -0.8807, -0.9306, -0.5580, -0.2773,  0.0446, -0.1388, -1.4956,\n",
       "                      -0.0401, -1.0646, -0.0260, -0.3307, -0.9926, -0.9924, -0.7937, -0.2751],\n",
       "                     device='cuda:0')),\n",
       "             ('bn1.running_mean',\n",
       "              tensor([-3.9489e+00, -1.3311e+00,  6.8706e+00,  7.2641e-01,  4.6823e+00,\n",
       "                      -2.8950e+00, -6.7397e+00,  1.4251e+00,  1.5976e+00,  4.3206e-01,\n",
       "                       4.2223e+00, -1.7800e+00, -1.2576e-01, -2.4140e+00, -1.0562e+00,\n",
       "                      -7.2709e+00, -3.4353e+00,  4.3523e-01,  3.4821e+00, -3.5322e+00,\n",
       "                       1.8788e+00,  8.0834e-02,  7.2403e-02, -2.4996e+00, -3.4952e+00,\n",
       "                      -1.0541e+00, -1.4587e+00,  5.8725e-01,  4.0651e-01,  1.9906e-01,\n",
       "                      -3.4574e+00, -4.0003e+00, -6.4013e+00,  2.0536e+00, -3.0956e+00,\n",
       "                       1.3659e+00, -8.4009e-01,  1.4656e+00, -1.1056e+00, -1.5121e+00,\n",
       "                      -3.8601e+00,  5.8784e-02,  9.5111e-01,  1.8389e+00, -2.7256e+00,\n",
       "                      -2.2120e+00, -8.2703e-01, -9.3403e-04,  1.6785e+00,  5.2339e+00,\n",
       "                       2.1505e+00,  2.0939e+00,  1.3899e+00,  1.7996e+00,  4.6618e+00,\n",
       "                      -5.8910e+00, -6.6087e-01, -3.5113e+00, -3.0627e+00, -9.5910e+00,\n",
       "                      -4.9292e+00, -5.2573e+00, -1.7773e+00,  6.4842e+00,  6.9767e-01,\n",
       "                       2.0494e+00,  2.7236e+00,  2.1577e+00,  1.2149e+00, -2.7879e+00,\n",
       "                      -5.2367e+00,  1.8519e+00, -2.3211e+00, -6.0905e+00, -3.7588e+00,\n",
       "                       1.2452e-01,  5.3067e+00, -1.8270e+00, -1.0130e+00,  3.1740e+00,\n",
       "                      -3.6314e+00, -5.4564e+00, -4.3606e-02,  8.7342e-01,  1.5728e+00,\n",
       "                      -1.2650e-01,  4.6457e-01, -1.4756e+00, -2.1755e+00,  3.3227e+00,\n",
       "                       1.6733e-01, -3.7412e+00,  1.7263e+00, -3.4873e+00, -7.2685e+00,\n",
       "                       2.0349e-01,  3.8383e+00,  1.6710e+00, -2.1518e+00,  3.0740e-01,\n",
       "                      -4.2963e+00,  1.3075e+00, -1.8271e+00, -1.6031e-01,  5.9130e-01,\n",
       "                      -6.7297e+00, -1.1641e+00, -6.3981e-01, -4.1961e-01, -4.9376e+00,\n",
       "                      -3.9692e+00,  8.7958e-01, -3.8560e+00, -2.6972e+00,  1.0206e+00,\n",
       "                       3.0964e-03, -3.0476e+00, -4.5821e+00,  1.6718e+00, -4.5222e-01,\n",
       "                       4.7295e+00, -5.0606e+00, -4.6696e-02, -1.2081e+00, -6.5485e+00,\n",
       "                      -7.6205e+00, -6.6543e+00,  4.8242e-01, -2.0805e+00, -4.6243e-02,\n",
       "                      -1.3252e+00, -4.5536e+00,  3.4140e+00, -1.3992e+00,  1.4675e+00,\n",
       "                      -1.3464e+00, -5.1193e+00,  5.5165e-01, -2.1855e+00,  2.5277e+00,\n",
       "                       9.7107e+00,  6.7248e-02, -4.2599e+00,  1.4064e-01,  3.2887e-01,\n",
       "                      -3.3945e-01, -1.1473e+00,  6.0458e-01, -2.5688e+00, -5.3477e+00,\n",
       "                       2.0004e+00, -3.7087e+00,  4.1803e+00,  2.5387e+00,  1.1218e+00,\n",
       "                      -4.3529e-01, -4.1004e+00, -1.0696e+00, -4.2811e+00, -3.0183e+00,\n",
       "                       1.0654e+00,  1.8201e+00, -3.0196e+00, -2.7719e+00, -6.5936e+00,\n",
       "                      -2.3754e+00, -1.0692e-02,  1.2882e+00,  2.4451e+00, -1.4586e+00,\n",
       "                      -1.3767e+00, -7.5958e-01, -4.4104e-02, -3.5022e+00,  1.4010e+00,\n",
       "                       1.4319e-01,  4.1941e+00,  5.4976e+00,  4.6152e+00,  4.8021e-02,\n",
       "                       1.5742e+00,  2.2890e+00,  5.3337e+00, -1.1793e+00,  1.6846e+00,\n",
       "                       2.5505e+00, -4.5297e+00, -1.0813e+00, -1.2060e+00, -4.7780e+00,\n",
       "                       3.6705e+00, -8.4678e-01, -3.4833e+00,  7.0925e+00, -1.0676e-01,\n",
       "                       8.7619e-01,  2.6599e+00,  3.1160e+00,  3.9166e-01, -4.8824e+00,\n",
       "                      -1.0414e+00,  2.5058e+00, -4.9455e+00, -9.6055e-01,  5.2953e+00,\n",
       "                       3.4020e+00,  2.5900e+00,  2.9060e+00,  4.5986e+00, -4.5860e-02,\n",
       "                      -2.5903e-01,  1.1432e+00,  1.4937e+00, -4.6205e-01,  2.4315e+00,\n",
       "                      -1.6885e+00, -3.0747e+00,  1.8969e+00, -1.5868e+00, -4.4609e-01,\n",
       "                       2.0766e+00, -1.1464e+00, -6.5583e-01, -7.5649e-01,  2.9495e+00,\n",
       "                       2.2740e+00,  2.6411e+00, -5.9867e+00, -2.4796e+00, -2.1895e+00,\n",
       "                      -4.1716e-02, -1.1525e+01,  2.1341e+00, -1.0682e-01, -8.2271e+00,\n",
       "                       3.4846e+00,  1.3320e+00, -4.2415e-01,  1.5629e+00, -5.5036e+00,\n",
       "                       3.5920e+00, -1.0043e-01,  6.8609e-01, -2.4704e+00,  6.7873e+00,\n",
       "                      -1.1607e+00,  1.5163e+00, -1.0985e+00, -1.1933e+00,  8.3688e-01,\n",
       "                       3.0122e+00,  6.8399e+00,  1.1788e+00, -5.3849e+00, -3.1059e+00,\n",
       "                      -3.1605e+00, -1.7722e+00,  5.2716e+00, -4.3246e+00,  8.6745e-01,\n",
       "                       2.6395e+00,  2.6455e+00, -6.4004e+00, -1.4556e+00, -3.0913e+00,\n",
       "                       8.6450e-01, -3.4671e+00, -6.5154e+00, -2.1653e+00, -3.6868e-01,\n",
       "                       8.9461e-02, -3.8151e+00,  3.3549e-01, -5.8521e+00,  2.0279e+00,\n",
       "                       3.2654e+00, -1.7323e+00, -3.6183e+00,  3.0378e+00, -4.6252e+00,\n",
       "                      -3.6170e+00,  8.2074e-01,  7.5259e-01, -1.1365e+00, -4.1253e+00,\n",
       "                      -4.3119e+00,  3.7506e+00,  1.7806e+00,  9.9379e-01, -1.2041e+00,\n",
       "                      -1.0713e+00,  1.5168e+00,  1.5466e+00, -2.6202e+00, -6.0466e+00,\n",
       "                       2.4303e-01,  3.8982e+00,  2.6525e-01, -7.1649e+00,  1.3678e+00,\n",
       "                      -5.0195e+00, -9.7259e-01,  2.0972e+00, -4.1541e+00, -2.7491e+00,\n",
       "                      -1.2367e+00,  1.2025e+00, -1.8333e-01, -2.8683e-01, -3.3389e+00,\n",
       "                      -9.4993e-01,  4.2832e-01, -9.3731e-01, -8.1128e+00, -3.4880e+00,\n",
       "                      -2.3525e+00, -3.6782e+00, -1.9240e+00, -6.0060e+00, -3.5308e+00,\n",
       "                      -4.1100e-01, -2.2796e+00, -3.6491e+00, -6.2144e+00, -4.9412e+00,\n",
       "                      -1.8729e+00, -8.2612e+00, -4.4967e+00,  3.8127e+00,  4.4703e+00,\n",
       "                       7.8851e-01,  5.6515e-01,  7.3872e-01,  4.4463e+00, -3.2730e+00,\n",
       "                       1.1360e+00, -5.2167e+00,  3.2238e+00,  1.1245e+00,  2.3242e+00,\n",
       "                       2.9086e+00, -4.0326e+00, -1.9254e+00, -2.5745e+00, -3.7368e+00,\n",
       "                       4.6746e+00, -1.1976e+00, -2.1797e+00, -1.1354e+00, -5.5426e+00,\n",
       "                       4.8424e+00, -3.0715e-01,  1.3623e+00, -6.6364e-01,  3.2890e+00,\n",
       "                      -5.4627e-01, -2.2502e+00, -6.1291e-01, -1.0708e+00, -2.3067e+00,\n",
       "                       1.4146e+00,  1.6675e+00, -1.9374e+00, -1.8808e+00,  2.0644e+00,\n",
       "                      -4.5695e-01, -6.2305e+00,  2.2809e+00,  3.1768e-01, -1.2137e+00,\n",
       "                      -5.3138e-01, -9.7792e-01,  8.6188e+00,  2.1307e+00,  1.8351e-01,\n",
       "                      -3.8334e+00,  5.5452e+00,  1.7985e+00,  2.1200e+00, -4.9836e+00,\n",
       "                      -1.5448e-01,  1.5809e+00,  6.0343e+00,  5.6050e-01, -1.3629e+00,\n",
       "                       3.3292e+00,  5.2964e-01,  5.5475e-02, -1.5034e+00, -3.7040e+00,\n",
       "                       5.3341e+00,  3.6638e+00,  1.4821e-02,  3.5136e-01,  6.3323e-01,\n",
       "                       2.6778e+00,  3.9547e-02, -1.1416e+00, -7.8015e+00,  9.4141e-01],\n",
       "                     device='cuda:0')),\n",
       "             ('bn1.running_var',\n",
       "              tensor([9.4510e+01, 8.5102e+01, 9.2295e+01, 2.8103e+01, 2.0297e+02, 5.2396e+01,\n",
       "                      7.4701e+01, 1.0546e+02, 1.7734e+01, 4.4927e+01, 1.9329e+02, 3.9473e+01,\n",
       "                      4.5667e+01, 7.9725e+01, 5.3930e+01, 1.0440e+02, 8.8231e+01, 2.9700e+01,\n",
       "                      3.6140e+01, 1.2620e+02, 2.4142e+02, 5.3567e+01, 2.2142e+02, 1.1200e+02,\n",
       "                      1.0289e+02, 5.6901e+01, 5.0301e+01, 6.3808e+01, 1.1532e+02, 9.5070e+01,\n",
       "                      8.4217e+01, 1.6978e+02, 7.2935e+01, 4.6540e+01, 1.4414e+02, 3.4535e+02,\n",
       "                      6.5271e+01, 4.7411e+01, 3.0436e+01, 6.4153e+01, 6.1554e+01, 6.8780e+02,\n",
       "                      1.6390e+02, 1.0536e+02, 1.1791e+01, 6.3879e+01, 1.5127e+02, 2.8372e+01,\n",
       "                      7.3427e+01, 8.6745e+01, 5.6473e+01, 5.3689e+01, 1.0863e+02, 1.1144e+02,\n",
       "                      5.5423e+01, 2.7639e+02, 4.1820e+01, 2.3738e+01, 4.8408e+01, 6.8551e+01,\n",
       "                      2.5701e+02, 4.5288e+01, 8.8756e+01, 1.4084e+02, 7.4974e+01, 6.8178e+01,\n",
       "                      6.2862e+01, 8.1544e+01, 1.1508e+02, 5.9805e+01, 9.3709e+01, 4.3380e+01,\n",
       "                      6.8046e+01, 1.5767e+02, 9.0201e+01, 3.3923e+01, 4.8687e+01, 8.0754e+01,\n",
       "                      1.2552e+02, 3.8095e+01, 1.3059e+02, 3.9603e+01, 1.4452e+00, 4.3455e+01,\n",
       "                      4.6317e+01, 1.1340e-01, 2.3800e+02, 7.6745e+01, 2.6472e+01, 1.7624e+02,\n",
       "                      5.0387e+01, 8.3223e+01, 5.0161e+01, 2.7523e+01, 1.9858e+02, 4.7850e+01,\n",
       "                      6.9202e+01, 8.8856e+01, 2.3355e+02, 5.5110e+01, 7.4753e+01, 1.1169e+02,\n",
       "                      1.3476e+02, 4.8153e+01, 1.6774e+02, 7.6715e+01, 3.7355e+01, 2.3436e+01,\n",
       "                      1.6721e+01, 1.4624e+02, 3.2924e+01, 1.3223e+02, 1.0643e+02, 1.2405e+02,\n",
       "                      8.1670e+01, 1.8322e+02, 5.1480e+01, 4.6088e+01, 1.0020e+02, 2.1837e+02,\n",
       "                      9.3609e+01, 4.2361e+01, 4.4051e+01, 1.9907e+02, 6.8995e+01, 9.5932e+01,\n",
       "                      2.6444e+02, 9.3500e+00, 1.0337e+02, 2.1820e-01, 3.3687e+01, 6.8575e+01,\n",
       "                      2.1838e+02, 1.3531e+02, 1.4009e+02, 2.6297e+02, 7.4346e+01, 7.7374e+01,\n",
       "                      4.5806e+01, 4.5535e+01, 9.0106e+01, 6.0092e+01, 1.0183e+02, 5.4509e+01,\n",
       "                      8.3874e+01, 5.0673e+01, 8.4693e+01, 1.1765e+02, 1.0140e+02, 7.2900e+01,\n",
       "                      5.9249e+01, 6.4696e+01, 1.4330e+02, 5.5659e+01, 8.0592e+01, 8.2447e+01,\n",
       "                      5.2096e+01, 1.6199e+01, 5.6987e+01, 4.4359e+01, 2.4240e+01, 2.8070e+02,\n",
       "                      4.2323e+01, 1.3611e+02, 8.0208e+01, 2.5146e+02, 8.5972e+01, 9.9245e+01,\n",
       "                      1.0860e+02, 1.2155e+02, 1.3911e+02, 1.3746e+01, 2.2838e-01, 8.6300e+01,\n",
       "                      7.4556e+01, 3.5398e+01, 1.3626e+02, 1.4262e+02, 1.6630e+02, 1.5942e+02,\n",
       "                      2.1718e+01, 2.8724e+02, 1.1347e+02, 1.4658e+02, 5.9614e+01, 1.2631e+01,\n",
       "                      1.4847e+02, 1.1591e+02, 1.7796e+01, 9.3136e+01, 4.6142e+01, 4.2572e+01,\n",
       "                      2.5034e+02, 5.0159e+01, 5.2480e+01, 1.0762e+02, 2.6981e+01, 1.1478e+02,\n",
       "                      1.4554e+02, 1.3690e+02, 4.6812e+01, 5.2367e+01, 6.5615e+01, 7.8730e+01,\n",
       "                      5.9228e+01, 1.5773e+02, 1.3122e+02, 9.4429e+01, 4.9174e+01, 4.6564e-01,\n",
       "                      1.2737e+02, 4.1751e+01, 8.5830e+01, 1.0196e+02, 4.7934e+01, 6.2274e+01,\n",
       "                      9.2896e+01, 1.6840e+02, 1.5950e+02, 1.8646e+02, 1.0088e+02, 9.9037e+01,\n",
       "                      1.5365e+02, 6.6710e+01, 2.0399e+02, 1.1858e+02, 1.7020e+02, 6.2832e+01,\n",
       "                      1.3187e+02, 1.1775e+02, 6.0304e+01, 1.2749e+02, 1.5615e+02, 9.7415e-02,\n",
       "                      8.7869e+01, 1.1529e+02, 5.1512e+01, 1.0787e+01, 5.9825e+01, 1.1115e+02,\n",
       "                      1.1041e+02, 2.7430e+01, 2.3008e+01, 8.4120e+01, 9.0179e+01, 1.8597e+02,\n",
       "                      1.2282e+02, 3.2567e+01, 2.0965e+02, 3.9224e+01, 1.4632e+02, 5.5061e+01,\n",
       "                      1.8161e+01, 3.6972e+01, 5.3800e+01, 4.2243e+01, 6.6794e+01, 5.0649e+01,\n",
       "                      1.3227e+02, 8.2037e+01, 1.4790e+01, 3.7890e+01, 1.4658e+02, 5.2906e+01,\n",
       "                      1.1495e+02, 1.3014e+02, 1.3855e+02, 4.2111e+01, 5.7166e+01, 5.8732e+01,\n",
       "                      7.6044e+01, 6.4015e+01, 8.5538e-01, 1.2636e+02, 7.0907e+01, 7.6529e+01,\n",
       "                      3.3399e+01, 1.3813e+02, 1.8124e+02, 3.1039e+01, 4.6707e+01, 1.2319e+02,\n",
       "                      1.1182e+01, 1.3429e+02, 2.1292e+02, 9.1313e+01, 7.2591e+01, 1.0942e+02,\n",
       "                      8.6951e+01, 1.0199e+02, 1.9943e+02, 4.9707e+01, 3.3796e+01, 1.4927e+02,\n",
       "                      1.6317e+02, 1.4771e+02, 8.7171e+01, 2.7977e+01, 1.1845e+02, 1.4865e+02,\n",
       "                      2.0929e+02, 1.9272e+02, 8.7079e+01, 8.5442e+01, 4.2835e+01, 1.9206e+02,\n",
       "                      8.1538e+01, 9.9584e+01, 6.4455e+01, 2.6299e+02, 2.1223e+02, 8.6288e+01,\n",
       "                      1.5603e+02, 9.7233e+01, 1.8433e+01, 1.8896e+01, 1.4131e+02, 1.3284e+02,\n",
       "                      1.6761e+02, 8.7254e+01, 2.0309e+02, 1.8963e+01, 8.1993e+01, 1.2417e+02,\n",
       "                      1.4524e+02, 7.3016e+01, 2.2587e+02, 1.0144e+02, 6.3364e+01, 4.5409e+01,\n",
       "                      1.3403e+02, 1.4729e+02, 2.7819e+02, 1.2765e+02, 1.0183e+02, 9.5174e+01,\n",
       "                      1.4287e+02, 4.0373e+01, 4.8914e+01, 1.6627e+02, 6.4295e+01, 1.1606e+02,\n",
       "                      6.6373e+01, 3.4984e+01, 9.3022e+01, 5.6325e+01, 1.3527e+01, 8.4441e+01,\n",
       "                      2.0073e+02, 2.9292e+02, 7.6072e+01, 1.3051e+02, 6.3142e+01, 7.5467e+01,\n",
       "                      1.5963e+02, 4.5274e+01, 6.5241e+01, 7.6525e+01, 7.2024e+01, 2.3320e+01,\n",
       "                      1.1987e+02, 7.9689e+01, 8.8818e+01, 1.7545e+01, 2.9147e+01, 2.1313e+01,\n",
       "                      7.4751e+01, 8.7771e+01, 4.4311e+01, 2.1349e+01, 9.6227e+01, 2.5904e+02,\n",
       "                      1.9341e+02, 4.1418e+01, 8.2224e+01, 4.2157e+01, 2.1549e+02, 4.8335e+01,\n",
       "                      1.7728e+02, 5.4990e+01, 1.0678e+02, 4.3109e+01, 4.3864e+02, 3.1182e+01,\n",
       "                      5.7120e+01, 8.7540e+01, 4.9780e+01, 1.4432e+02, 3.7860e+01, 2.8852e+02,\n",
       "                      1.5384e+02, 4.5486e+01, 1.3790e-01, 1.6562e+02, 8.3068e+01, 5.4096e+01,\n",
       "                      8.3621e+01, 1.7661e+02, 1.1022e+02, 1.5147e+01], device='cuda:0')),\n",
       "             ('bn1.num_batches_tracked', tensor(1019800, device='cuda:0')),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 1.3167,  1.6259,  0.2731,  ...,  0.7774,  0.0805, -0.3608],\n",
       "                      [-0.2028,  0.1403, -0.2040,  ..., -0.0829, -0.0382,  0.0948],\n",
       "                      [ 1.5740, -0.8397,  0.7684,  ..., -0.9747, -1.0626, -0.1969],\n",
       "                      ...,\n",
       "                      [-0.9036,  0.0873, -0.5725,  ..., -0.2137,  0.1369, -0.2662],\n",
       "                      [-1.1477, -2.0482,  0.0071,  ..., -0.7272,  0.7454, -0.4204],\n",
       "                      [ 3.0799, -1.4056, -2.5157,  ..., -0.4141,  0.9741, -0.3599]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc2.bias',\n",
       "              tensor([-3.1773e+00, -8.0947e-02, -8.2755e-01, -2.6553e-01, -7.6376e-02,\n",
       "                      -4.9874e-01,  1.9938e-01, -1.2272e-02,  7.2113e-01, -9.3364e-02,\n",
       "                      -1.6313e-01, -7.8161e-02, -2.2510e+00, -2.6081e+00, -2.8313e-01,\n",
       "                      -2.5810e+00,  2.1874e-01,  6.8881e-02, -1.0697e+00, -2.1139e-01,\n",
       "                       5.7429e-01, -8.7795e-02, -1.1314e+00,  3.1998e-02, -3.1725e-01,\n",
       "                      -1.6657e-01,  3.2943e-01, -1.1052e+00, -5.8045e-01, -1.3616e-01,\n",
       "                      -8.2024e-01, -9.1493e-01,  5.8647e-02,  8.3143e-02, -1.0442e-01,\n",
       "                       2.8056e-03, -1.2272e-02, -1.8097e-01, -3.0633e-02, -3.3579e-01,\n",
       "                      -1.3013e+00, -3.9851e-01, -3.0361e-01, -2.8917e-01, -7.8841e-02,\n",
       "                      -2.9140e-01,  1.3414e-01, -6.4805e-01,  4.6946e-01, -7.0168e-01,\n",
       "                      -8.9734e-01, -2.5176e-01, -1.4456e-01,  7.4811e-03, -7.8566e-02,\n",
       "                      -5.4112e-02, -7.5834e-01, -5.9028e-02, -2.4814e-01, -1.5531e+00,\n",
       "                      -1.3132e+00, -9.0653e-02, -9.6957e-02, -1.0094e-01, -1.1977e-01,\n",
       "                       5.3719e-01, -1.4514e+00,  2.2501e-01, -6.3437e-01, -1.5868e+00,\n",
       "                      -3.5305e-01, -2.4439e+00, -1.1887e+00, -8.4168e-01,  1.3343e-01,\n",
       "                      -8.4678e-02, -6.2758e-02, -2.0197e-01, -2.3999e+00,  1.2679e-02,\n",
       "                      -2.3436e-01, -3.1468e-01, -1.6437e+00, -2.1185e+00,  8.0071e-03,\n",
       "                      -2.4240e-01, -3.5605e-01, -8.5645e-01, -1.6310e-01, -1.5635e+00,\n",
       "                      -7.7049e-01, -4.0751e-02,  1.9110e-01, -1.4490e-02, -8.7399e-02,\n",
       "                      -8.3914e-02,  4.4858e-02,  3.9407e-01, -5.2839e-01, -1.6485e+00,\n",
       "                      -9.2632e-02,  4.3893e-01, -3.8550e-01, -8.1032e-01, -2.6944e+00,\n",
       "                      -5.6289e-01,  5.9789e-01, -8.5887e-02, -6.4312e-01, -8.8204e-01,\n",
       "                       1.3494e-01, -1.5957e+00, -7.3999e-01,  3.8781e-04, -1.2196e+00,\n",
       "                      -4.9111e-02,  7.1441e-02, -4.1810e-03, -2.5143e-01, -2.4592e-01,\n",
       "                      -1.2548e-01, -1.7323e-01, -1.3920e-01, -7.8993e-01, -1.4389e+00,\n",
       "                       5.1384e-01, -5.8728e-02, -4.9818e-01, -2.4088e-01,  2.2297e-01,\n",
       "                       5.3306e-01, -5.1534e-01, -6.8307e-02, -6.9495e-02, -3.2467e-02,\n",
       "                      -5.2080e-01, -1.4336e-01, -1.2682e+00, -7.1352e-02, -1.5293e+00,\n",
       "                      -1.3505e+00, -6.2484e-01, -6.7727e-02, -1.6572e-01, -6.1209e-01,\n",
       "                      -2.4683e-02,  4.6979e-01, -1.9082e-01, -1.6223e-01, -4.8329e-01,\n",
       "                      -2.4957e-01, -1.5769e+00,  4.6962e-02, -1.6469e+00, -1.1336e-01,\n",
       "                      -1.0391e-01, -1.7392e+00, -2.3838e-02, -1.1166e-01,  3.2280e-01,\n",
       "                      -1.5578e-02, -9.9113e-01, -7.9724e-02, -1.0612e+00,  1.0912e+00,\n",
       "                       9.0352e-03, -7.9899e-02,  1.9218e-01, -3.2107e-02, -5.4411e-01,\n",
       "                      -9.9534e-01,  3.2957e-02, -4.0782e-01, -2.4112e+00, -1.3256e+00,\n",
       "                      -1.2968e+00, -5.6374e-04, -2.1627e+00,  6.8294e-01, -1.7741e+00,\n",
       "                      -1.2362e-01, -2.8814e-02, -1.6591e-01,  2.2748e-02, -1.9006e-01,\n",
       "                      -7.0263e-01,  5.5705e-03, -4.0864e-01, -5.8706e-01,  1.7797e-01,\n",
       "                      -7.7552e-01, -7.9143e-01, -2.1444e+00, -1.0569e+00, -1.5632e-01,\n",
       "                      -2.8381e-01, -7.6559e-02, -9.9386e-01, -1.2079e-01, -6.9322e-01,\n",
       "                      -6.2930e-02, -2.0324e+00,  4.2192e-02,  4.2072e-01, -1.8407e-01,\n",
       "                      -9.9537e-01,  1.6143e-01,  2.4000e-01, -8.5418e-02, -7.5099e-02,\n",
       "                      -9.7558e-01, -2.9290e+00, -2.5787e-01, -1.3996e+00, -3.5635e-02,\n",
       "                      -2.5612e-01, -1.0888e+00,  4.6834e-01, -2.4048e-02, -1.2821e+00,\n",
       "                      -7.1917e-02,  2.7058e-01, -5.9002e-01, -8.0718e-01, -9.5763e-01,\n",
       "                      -4.4927e-02, -4.3069e-03, -9.4618e-02, -4.6457e-01, -8.2039e-01,\n",
       "                       3.6891e-01, -1.6861e+00, -8.5238e-02, -1.9309e+00, -7.4008e-02,\n",
       "                      -1.3235e+00,  1.1507e-01, -1.2424e+00, -7.6926e-01, -1.0406e-01,\n",
       "                      -2.0646e+00, -6.1453e-01, -1.4199e+00, -1.0782e-01, -3.3223e-01,\n",
       "                      -2.4008e+00, -1.2078e-01,  9.1550e-02, -1.0447e+00, -1.7707e-01,\n",
       "                      -1.8995e+00, -8.5211e-01, -1.8268e+00, -2.3666e+00, -1.1750e-01,\n",
       "                      -6.9176e-02, -9.7523e-02, -1.4443e+00, -6.4087e-02, -3.6863e-01,\n",
       "                      -4.0504e-01, -4.0086e-01,  9.7891e-03, -6.4118e-02, -7.4905e-02,\n",
       "                      -7.9564e-01, -2.5979e+00,  1.4250e-01,  8.9860e-02, -1.2163e+00,\n",
       "                       3.3493e-01, -3.2151e-01, -1.6055e+00,  6.7519e-02, -5.5190e-01,\n",
       "                       7.5771e-02, -4.7450e-01, -2.0417e+00, -1.1180e+00, -9.1839e-02,\n",
       "                      -2.6446e-01, -2.6955e+00, -7.9834e-01, -9.0368e-01, -4.5446e-01,\n",
       "                      -7.6156e-02,  6.4433e-01,  1.0575e-01, -9.9022e-01, -2.7070e+00,\n",
       "                      -3.8133e-01, -6.9688e-01,  1.4004e-01, -9.0508e-02, -1.5060e-01,\n",
       "                      -4.4481e-01, -1.6361e+00,  7.2888e-03, -9.8307e-01,  3.9295e-01],\n",
       "                     device='cuda:0')),\n",
       "             ('fc3.weight',\n",
       "              tensor([[-0.4104, -0.1226, -1.3309,  ..., -0.3918, -0.0021,  0.0459],\n",
       "                      [ 0.0180,  0.0539,  0.6946,  ...,  0.2099, -0.7147,  0.2306],\n",
       "                      [-1.2244,  0.1069,  0.5891,  ...,  0.0617,  0.1670, -0.6930],\n",
       "                      [-0.2236,  0.2067, -1.1882,  ...,  0.5061,  0.0293,  0.5078]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc3.bias',\n",
       "              tensor([ 0.9914,  0.5383, -0.1551, -0.6265], device='cuda:0'))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_file = r'checkpoint_actor.pth'\n",
    "\n",
    "agent = agent = Agent(num_agents, state_size, action_size, 1)\n",
    "state_dict_actor = torch.load(actor_file)\n",
    "agent.actor_local.load_state_dict(state_dict_actor)\n",
    "state_dict_actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\agents\\lib\\site-packages\\torch\\nn\\functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = agent.act(states, add_noise=False) # select an action (for each agent)\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
